---
title:  "More classifiers"
excerpt: "md íŒŒì¼ì— ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ìœ¼ë¡œ ì‘ì„±í•˜ì—¬ Github ì›ê²© ì €ì¥ì†Œì— ì—…ë¡œë“œ í•´ë³´ì. ì—ë””í„°ëŠ” Visual Studio code ì‚¬ìš©! ë¡œì»¬ ì„œë²„ì—ì„œ í™•ì¸ë„ í•´ë³´ì. "

categories:
  - Blog
tags:
  - [Blog, jekyll, Github, Git]

toc: true
toc_sticky: true
 
date: 2020-05-25
last_modified_at: 2020-05-25
---
# ìš”ë¦¬ ë¶„ë¥˜ê¸° 1

ì´ ë‹¨ì›ì—ì„œëŠ” ìš”ë¦¬ì— ëŒ€í•œ ê· í˜• ì¡íŒ ê¹¨ë—í•œ ë°ì´í„°ë¡œ ê°€ë“ ì°¬ ì§€ë‚œ ë‹¨ì›ì—ì„œ ì €ì¥í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.


ë‹¤ì–‘í•œ ë¶„ë¥˜ê¸°ì™€ í•¨ê»˜ ì´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ _ì¬ë£Œ ê·¸ë£¹ì„ ê¸°ë°˜ìœ¼ë¡œ ì£¼ì–´ì§„ êµ­ê°€ ìš”ë¦¬ë¥¼ ì˜ˆì¸¡_í•©ë‹ˆë‹¤. ê·¸ë ‡ê²Œ í•˜ëŠ” ë™ì•ˆ ë¶„ë¥˜ ì‘ì—…ì— ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•  ìˆ˜ ìˆëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³¼ ê²ƒì…ë‹ˆë‹¤.

## [Pre-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/21/)
# ì¤€ë¹„

ì™„ë£Œí–ˆë‹¤ê³  ê°€ì •í•˜ë©´[Lesson 1](2022-05-07-se1.md),ì´ 4ê°œì˜ ë ˆìŠ¨ì„ ìœ„í•´ ë£¨íŠ¸ `/data` í´ë”ì— _cleaned_cuisines.csv_ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.

## êµ­ê°€ ìš”ë¦¬ë¥¼ ì˜ˆì¸¡í•˜ë‹¤


1. ì´ ê°•ì˜ì˜ _notebook.ipynb_ í´ë”ì—ì„œ Pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í•¨ê»˜ í•´ë‹¹ íŒŒì¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    
ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  


2. ì´ì œ ì—¬ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¶”ê°€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

3. í›ˆë ¨ì„ ìœ„í•´ X ë° y ì¢Œí‘œë¥¼ ë‘ ê°œì˜ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤. `cuisine`ì€ ë ˆì´ë¸” ë°ì´í„° í”„ë ˆì„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```


ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œë©ë‹ˆë‹¤.

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

4.í•´ë‹¹ `Unnamed: 0` ì—´ê³¼ `cuisine` ì—´ì„ ì‚­ì œí•˜ê³  `drop()`ì„ í˜¸ì¶œí•©ë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ë°ì´í„°ë¥¼ í•™ìŠµ ê°€ëŠ¥í•œ ê¸°ëŠ¥ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

   ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |


ì´ì œ ëª¨ë¸ì„ í›ˆë ¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!

## ë¶„ë¥˜ê¸° ì„ íƒ


ì´ì œ ë°ì´í„°ê°€ ì •ë¦¬ë˜ê³  í•™ìŠµí•  ì¤€ë¹„ê°€ ë˜ì—ˆìœ¼ë¯€ë¡œ ì‘ì—…ì— ì‚¬ìš©í•  ì•Œê³ ë¦¬ì¦˜ì„ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤


Scikit-learnì€ ì§€ë„ í•™ìŠµ(Supervised Learning)ì—ì„œ ë¶„ë¥˜ë¥¼ ê·¸ë£¹í™”í•˜ê³  í•´ë‹¹ ë²”ì£¼ì—ì„œ ë¶„ë¥˜í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [The variety](https://scikit-learn.org/stable/supervised_learning.html) ì²«ëˆˆì— ìƒë‹¹íˆ ì–´ë¦¬ë‘¥ì ˆí•˜ë‹¤. ë‹¤ìŒ ë°©ë²•ì—ëŠ” ëª¨ë‘ ë¶„ë¥˜ ê¸°ìˆ ì´ í¬í•¨ë©ë‹ˆë‹¤

- ì„ í˜• ëª¨ë¸
- ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ 
- í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•
- ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒ
- ê°€ìš°ìŠ¤ í”„ë¡œì„¸ìŠ¤
- ì˜ì‚¬ê²°ì •ë‚˜ë¬´
- ì•™ìƒë¸” ë°©ì‹(íˆ¬í‘œ ë¶„ë¥˜ê¸°)
- ë‹¤ì¤‘ í´ë˜ìŠ¤ ë° ë‹¤ì¤‘ ì¶œë ¥ ì•Œê³ ë¦¬ì¦˜(ë‹¤ì¤‘ í´ë˜ìŠ¤ ë° ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜, ë‹¤ì¤‘ í´ë˜ìŠ¤ ë‹¤ì¤‘ ì¶œë ¥ ë¶„ë¥˜)

> ë‹¹ì‹ ì€ ë˜í•œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ [neural networks to classify data](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), 
ê·¸ëŸ¬ë‚˜ ê·¸ê²ƒì€ ì´ ìˆ˜ì—…ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚©ë‹ˆë‹¤.

### ì–´ë–¤ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•  ê²ƒì¸ê°€?


ê·¸ë ‡ë‹¤ë©´ ì–´ë–¤ ë¶„ë¥˜ê¸°ë¥¼ ì„ íƒí•´ì•¼ í• ê¹Œìš”? ì¢…ì¢… ì—¬ëŸ¬ ê°€ì§€ë¥¼ ì‹¤í–‰í•˜ê³  ì¢‹ì€ ê²°ê³¼ë¥¼ ì°¾ëŠ” ê²ƒì´ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.Scikit-learnì€ ë‹¤ìŒì„ ì œê³µí•©ë‹ˆë‹¤.[side-by-side comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) ìƒì„±ëœ ë°ì´í„°ì„¸íŠ¸ì—ì„œKNeighbors, SVC ë‘ ê°€ì§€ ë°©ë²•, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB ë° QuadraticDiscrinationAnalysisë¥¼ ë¹„êµí•˜ì—¬ ì‹œê°í™”ëœ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.


![comparison of classifiers](comparison.png)
> Scikit-learnì˜ ë¬¸ì„œì—ì„œ ìƒì„±ëœ í”Œë¡¯

> AutoMLì€ í´ë¼ìš°ë“œì—ì„œ ì´ëŸ¬í•œ ë¹„êµë¥¼ ì‹¤í–‰í•˜ì—¬ ì´ ë¬¸ì œë¥¼ ê¹”ë”í•˜ê²Œ í•´ê²°í•˜ë¯€ë¡œ ë°ì´í„°ì— ê°€ì¥ ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Try it [here](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-15963-cxa)

### ë” ë‚˜ì€ ì ‘ê·¼ ë°©ì‹

ê·¸ëŸ¬ë‚˜ ì„±ê¸‰í•˜ê²Œ ì¶”ì¸¡í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ì¢‹ì€ ë°©ë²•ì€ ì´ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ë¥¼ ë”°ë¥´ëŠ” ê²ƒì…ë‹ˆë‹¤.[ML Cheat sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-15963-cxa).ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¬¸ì œì— ëŒ€í•´ ëª‡ ê°€ì§€ ì„ íƒ ì‚¬í•­ì´ ìˆìŒì„ ë°œê²¬í•©ë‹ˆë‹¤.

![cheatsheet for multiclass problems](cheatsheet.png)
> A section of Microsoft's Algorithm Cheat Sheet, detailing multiclass classification options

âœ… ì´ ì¹˜íŠ¸ ì‹œíŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì¸ì‡„í•˜ì—¬ ë²½ì— ê±¸ì–´ë‘ì‹­ì‹œì˜¤!

### ì¶”ë¦¬

ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ì œì•½ ì¡°ê±´ì„ ê°ì•ˆí•  ë•Œ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ”ì§€ ë´…ì‹œë‹¤.

- **ì‹ ê²½ë§ì´ ë„ˆë¬´ ë¬´ê²ìŠµë‹ˆë‹¤**. ê¹¨ë—í•˜ì§€ë§Œ ìµœì†Œí•œì˜ ë°ì´í„° ì„¸íŠ¸ì™€ ë…¸íŠ¸ë¶ì„ í†µí•´ ë¡œì»¬ë¡œ í›ˆë ¨ì„ ì‹¤í–‰í•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ê°ì•ˆí•  ë•Œ ì‹ ê²½ë§ì€ ì´ ì‘ì—…ì— ë„ˆë¬´ ë¬´ê²ìŠµë‹ˆë‹¤.
- **2ë“±ê¸‰ ë¶„ë¥˜ê¸° ì—†ìŒ**. ìš°ë¦¬ëŠ” ì¼ëŒ€ì¼(one-vs-all)ì„ ë°°ì œí•˜ê¸° ìœ„í•´ 2-í´ë˜ìŠ¤ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- **ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ ë˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ê°€ ì‘ë™í•  ìˆ˜ ìˆìŒ**. ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬ê°€ ì‘ë™í•˜ê±°ë‚˜ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë°ì´í„°ì— ëŒ€í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ê°€ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **Multiclass Boosted Decision TreesëŠ” ë‹¤ë¥¸ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤**. ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶€ìŠ¤íŠ¸ ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬ëŠ” ë¹„ëª¨ìˆ˜ì  ì‘ì—…ì— ê°€ì¥ ì í•©í•©ë‹ˆë‹¤. ìˆœìœ„ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì„¤ê³„ëœ ì‘ì—…ì´ë¯€ë¡œ ìš°ë¦¬ì—ê²Œ ìœ ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

### ì‚¬ì´í‚·ëŸ° ì‚¬ìš©í•˜ê¸°

ìš°ë¦¬ëŠ” Scikit-learnì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ì„í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Scikit-learnì—ì„œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. Take a look at the [parameters to pass](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

ë³¸ì§ˆì ìœ¼ë¡œ ìš°ë¦¬ê°€ Scikit-learnì— ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ìˆ˜í–‰í•˜ë„ë¡ ìš”ì²­í•  ë•Œ ì§€ì •í•´ì•¼ í•˜ëŠ” ë‘ ê°€ì§€ ì¤‘ìš”í•œ ë§¤ê°œë³€ìˆ˜ì¸ `multi_class`ì™€ `solver`ê°€ ìˆìŠµë‹ˆë‹¤. 'multi_class' ê°’ì€ íŠ¹ì • ë™ì‘ì„ ì ìš©í•©ë‹ˆë‹¤. ì†”ë²„ì˜ ê°’ì€ ì‚¬ìš©í•  ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ëª¨ë“  ì†”ë²„ê°€ ëª¨ë“  `multi_class` ê°’ê³¼ ì§ì„ ì´ë£° ìˆ˜ ìˆëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.

ë¬¸ì„œì— ë”°ë¥´ë©´ ë‹¤ì¤‘ í´ë˜ìŠ¤ì˜ ê²½ìš° í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.


- **'multi_class' ì˜µì…˜ì´ 'ovr'ë¡œ ì„¤ì •ëœ ê²½ìš° **one-vs-rest(OvR) ë°©ì‹ ì‚¬ìš©**
- `multi_class` ì˜µì…˜ì´ `multinomial`ë¡œ ì„¤ì •ëœ ê²½ìš° **êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤**. (í˜„ì¬ 'ë‹¤í•­ì‹' ì˜µì…˜ì€ 'lbfgs', 'sag', 'saga' ë° 'newton-cg' ì†”ë²„ì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.)"

> ğŸ“ì—¬ê¸°ì„œ 'scheme'ì€ 'ovr'(one-vs-rest) ë˜ëŠ” 'multinomial'ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ì‹¤ì œë¡œ ì´ì§„ ë¶„ë¥˜ë¥¼ ì§€ì›í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ì²´ê³„ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‘ì—…ì„ ë” ì˜ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [source](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> ğŸ“ 'í•´ê²°ì‚¬'ëŠ” "ìµœì í™” ë¬¸ì œì— ì‚¬ìš©í•  ì•Œê³ ë¦¬ì¦˜"ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤. [source](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learnì€ ì†”ë²„ê°€ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë°ì´í„° êµ¬ì¡°ê°€ ì œì‹œí•˜ëŠ” ë‹¤ì–‘í•œ ë¬¸ì œë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ ë‹¤ìŒ í‘œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

![solvers](images/solvers.png)

## ë°ì´í„°ë¥¼ ë¶„í• 

ì´ì „ ìˆ˜ì—…ì—ì„œ ìµœê·¼ì— í›„ìì— ëŒ€í•´ ë°°ì› ê¸° ë•Œë¬¸ì— ì²« ë²ˆì§¸ í›ˆë ¨ ì‹œë„ì— ëŒ€í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
`train_test_split()`ì„ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## ë¡œì§€ìŠ¤í‹± íšŒê·€ ì ìš©


ë‹¤ì¤‘ í´ë˜ìŠ¤ ì‚¬ë¡€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ ì‚¬ìš©í•  _scheme_ê³¼ ì„¤ì •í•  _solver_ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ì¤‘ í´ë˜ìŠ¤ ì„¤ì • ë° **liblinear** ì†”ë²„ì™€ í•¨ê»˜ LogisticRegressionì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨í•©ë‹ˆë‹¤.

1. multi_classë¥¼ 'ovr'ë¡œ ì„¤ì •í•˜ê³  ì†”ë²„ë¥¼ 'liblinear'ë¡œ ì„¤ì •í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    âœ… ì¢…ì¢… ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë˜ëŠ” `lbfgs`ì™€ ê°™ì€ ë‹¤ë¥¸ ì†”ë²„ë¥¼ ì‚¬ìš©í•´ ë³´ì‹­ì‹œì˜¤.

    > Note, use Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) function to flatten your data when needed.

    ì •í™•ë„ëŠ” **80%** ì´ìƒìœ¼ë¡œ ì¢‹ìŠµë‹ˆë‹¤!

2. í•œ í–‰ì˜ ë°ì´í„°(#50)ë¥¼ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì´ ëª¨ë¸ì´ ì‘ë™í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    ê²°ê³¼ê°€ ì¸ì‡„ë©ë‹ˆë‹¤.

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   âœ… ë‹¤ë¥¸ í–‰ ë²ˆí˜¸ë¥¼ ì‹œë„í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤


3. ë” ê¹Šì´ íŒŒê³  ë“¤ë©´ ì´ ì˜ˆì¸¡ì˜ ì •í™•ì„±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    
ê²°ê³¼ê°€ ì¸ì‡„ë©ë‹ˆë‹¤. ì¸ë„ ìš”ë¦¬ê°€ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì¶”ì¸¡ì…ë‹ˆë‹¤.

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    âœ… ëª¨ë¸ì´ ì´ê²ƒì´ ì¸ë„ ìš”ë¦¬ë¼ê³  í™•ì‹ í•˜ëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆê¹Œ?

4. íšŒê·€ ìˆ˜ì—…ì—ì„œ í–ˆë˜ ê²ƒì²˜ëŸ¼ ë¶„ë¥˜ ë³´ê³ ì„œë¥¼ ì¸ì‡„í•˜ì—¬ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì–»ìœ¼ì‹­ì‹œì˜¤.

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | precision | recall | f1-score | support |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinese      | 0.73      | 0.71   | 0.72     | 229     |
    | indian       | 0.91      | 0.93   | 0.92     | 254     |
    | japanese     | 0.70      | 0.75   | 0.72     | 220     |
    | korean       | 0.86      | 0.76   | 0.81     | 242     |
    | thai         | 0.79      | 0.85   | 0.82     | 254     |
    | accuracy     | 0.80      | 1199   |          |         |
    | macro avg    | 0.80      | 0.80   | 0.80     | 1199    |
    | weighted avg | 0.80      | 0.80   | 0.80     | 1199    |

## ğŸš€Challenge

ì´ í•™ìŠµì—ì„œëŠ” ì •ë¦¬ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ë ¨ì˜ ì¬ë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ­ê°€ ìš”ë¦¬ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ì‹œê°„ì„ ë‚´ì–´ Scikit-learnì´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ì œê³µí•˜ëŠ” ë‹¤ì–‘í•œ ì˜µì…˜ì„ ì‚´í´ë³´ì‹­ì‹œì˜¤. ë¬´ëŒ€ ë’¤ì—ì„œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ì§€ ì´í•´í•˜ë ¤ë©´ 'í•´ê²°ì‚¬'ì˜ ê°œë…ì„ ë” ê¹Šì´ íŒŒí—¤ì³ ë³´ì„¸ìš”.

## [Post-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/22/)

## Review & Self Study

Dig a little more into the math behind logistic regression in [this lesson](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Assignment 

[Study the solvers](assignment.md)
