---
title:  "Yet other classifiers"
excerpt: "md íŒŒì¼ì— ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ìœ¼ë¡œ ì‘ì„±í•˜ì—¬ Github ì›ê²© ì €ì¥ì†Œì— ì—…ë¡œë“œ í•´ë³´ì. ì—ë””í„°ëŠ” Visual Studio code ì‚¬ìš©! ë¡œì»¬ ì„œë²„ì—ì„œ í™•ì¸ë„ í•´ë³´ì. "

categories:
  - Blog
tags:
  - [Blog, jekyll, Github, Git]

toc: true
toc_sticky: true
 
date: 2020-05-25
last_modified_at: 2020-05-25
---
# ìš”ë¦¬ ë¶„ë¥˜ê¸° 2

ì´ ë‘ ë²ˆì§¸ ë¶„ë¥˜ ìˆ˜ì—…ì—ì„œëŠ” ìˆ«ì ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë” ë§ì€ ë°©ë²•ì„ íƒìƒ‰í•©ë‹ˆë‹¤. ë˜í•œ í•˜ë‚˜ì˜ ë¶„ë¥˜ê¸°ë¥¼ ë‹¤ë¥¸ ë¶„ë¥˜ê¸°ë³´ë‹¤ ì„ íƒí•˜ëŠ” ê²°ê³¼ì— ëŒ€í•´ì„œë„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤.

## [Pre-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/23/)

### ì „ì œ ì¡°ê±´

ì´ì „ ê°•ì˜ë¥¼ ì™„ë£Œí–ˆê³  ì´ 4ê°œ ê°•ì˜ í´ë”ì˜ ë£¨íŠ¸ì— ìˆëŠ” _cleaned_cuisines.csv_ë¼ëŠ” `data` í´ë”ì— ì •ë¦¬ëœ ë°ì´í„°ì„¸íŠ¸ê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.

### ì¤€ë¹„

ì •ë¦¬ëœ ë°ì´í„° ì„¸íŠ¸ê°€ ìˆëŠ” _notebook.ipynb_ íŒŒì¼ì„ ë¡œë“œí•˜ê³  X ë° y ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ëª¨ë¸ êµ¬ì¶• í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.

## ë¶„ë¥˜ ì§€ë„

ì´ì „ì—ëŠ” Microsoftì˜ ì¹˜íŠ¸ ì‹œíŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì˜µì…˜ì— ëŒ€í•´ ë°°ì› ìŠµë‹ˆë‹¤. Scikit-learnì€ ì¶”ì •ê¸°ë¥¼ ì¢íˆëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ìœ ì‚¬í•˜ì§€ë§Œ ë” ì„¸ë¶„í™”ëœ ì¹˜íŠ¸ ì‹œíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤(ë¶„ë¥˜ê¸°ì˜ ë˜ ë‹¤ë¥¸ ìš©ì–´).

![ML Map from Scikit-learn](map.png)
> Tip: [visit this map online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) and click along the path to read documentation.

### ê³„íš

ì´ ì§€ë„ëŠ” ë°ì´í„°ë¥¼ ëª…í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ë‚˜ë©´ ê²°ì •ì— ì´ë¥´ëŠ” ê²½ë¡œë¥¼ ë”°ë¼ 'ê±¸ì„' ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.

- ìƒ˜í”Œì´ 50ê°œ ì´ìƒ ìˆìŠµë‹ˆë‹¤.
- ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ˆì¸¡í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.
- ë°ì´í„°ì— ë ˆì´ë¸”ì„ ì§€ì •í–ˆìŠµë‹ˆë‹¤.
- ìƒ˜í”Œì´ 100,000ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.
- âœ¨ ìš°ë¦¬ëŠ” ì„ í˜• SVCë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ê·¸ê²ƒì´ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ìš°ë¦¬ëŠ” ìˆ«ì ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì—
    - ìš°ë¦¬ëŠ” âœ¨ KNeighbors Classifierë¥¼ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
      - ê·¸ë˜ë„ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´ âœ¨ SVC ë° âœ¨ Ensemble Classifiersë¥¼ ì‹œë„í•˜ì‹­ì‹œì˜¤.

ì´ê²ƒì€ ë”°ë¼ê°€ê¸°ì— ë§¤ìš° ë„ì›€ì´ ë˜ëŠ” ê¸¸ì…ë‹ˆë‹¤.

## ë°ì´í„°ë¥¼ ë¶„í• 


ì´ ê²½ë¡œë¥¼ ë”°ë¼ ì‚¬ìš©í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.

1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```


2. í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## ì„ í˜• SVC ë¶„ë¥˜ê¸°

ì§€ì› ë²¡í„° í´ëŸ¬ìŠ¤í„°ë§(SVC)ì€ ML ê¸°ìˆ ì˜ ì§€ì› ë²¡í„° ë¨¸ì‹  ì œí’ˆêµ°ì˜ í•˜ìœ„ í•­ëª©ì…ë‹ˆë‹¤(ì•„ë˜ì—ì„œ ìì„¸íˆ ì•Œì•„ë³´ê¸°). ì´ ë°©ë²•ì—ì„œëŠ” 'ì»¤ë„'ì„ ì„ íƒí•˜ì—¬ ë ˆì´ë¸”ì„ í´ëŸ¬ìŠ¤í„°ë§í•˜ëŠ” ë°©ë²•ì„ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'C' ë§¤ê°œë³€ìˆ˜ëŠ” ë§¤ê°œë³€ìˆ˜ì˜ ì˜í–¥ì„ ê·œì œí•˜ëŠ” 'ì •ê·œí™”'ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì»¤ë„ì€ [several](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); ì—¬ê¸°ì„œëŠ” ì„ í˜• SVCë¥¼ í™œìš©í•˜ë„ë¡ 'ì„ í˜•'ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. í™•ë¥ ì€ ê¸°ë³¸ì ìœ¼ë¡œ 'ê±°ì§“'ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ í™•ë¥  ì¶”ì •ì¹˜ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ 'true'ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. í™•ë¥ ì„ ì–»ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ì„ê¸° ìœ„í•´ ì„ì˜ ìƒíƒœë¥¼ '0'ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

### ì„ í˜• SVC ì ìš©

ë¶„ë¥˜ê¸° ë°°ì—´ì„ ìƒì„±í•˜ì—¬ ì‹œì‘í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸í•˜ë©´ì„œ ì´ ë°°ì—´ì— ì ì§„ì ìœ¼ë¡œ ì¶”ê°€í•  ê²ƒì…ë‹ˆë‹¤.

1. ì„ í˜• SVCë¡œ ì‹œì‘:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```


2. ì„ í˜• SVCë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë³´ê³ ì„œë¥¼ ì¸ì‡„í•©ë‹ˆë‹¤.

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    
ê²°ê³¼ëŠ” ê½¤ ì¢‹ìŠµë‹ˆë‹¤.

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## K-Neighbors ë¶„ë¥˜ê¸°

K-NeighborsëŠ” ì§€ë„ í•™ìŠµ ë° ë¹„ì§€ë„ í•™ìŠµ ëª¨ë‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ML ë°©ë²•ì˜ "ì´ì›ƒ" ê³„ì—´ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ ë°©ë²•ì—ì„œëŠ” ë¯¸ë¦¬ ì •ì˜ëœ ìˆ˜ì˜ í¬ì¸íŠ¸ê°€ ìƒì„±ë˜ê³  ë°ì´í„°ì— ëŒ€í•´ ì¼ë°˜í™”ëœ ë ˆì´ë¸”ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ ì´ëŸ¬í•œ í¬ì¸íŠ¸ ì£¼ë³€ì— ë°ì´í„°ê°€ ìˆ˜ì§‘ë©ë‹ˆë‹¤.

### K-Neighbors ë¶„ë¥˜ê¸° ì ìš©

ì´ì „ ë¶„ë¥˜ê¸°ëŠ” í›Œë¥­í–ˆê³  ë°ì´í„°ì™€ ì˜ ì‘ë™í–ˆì§€ë§Œ ë” ë‚˜ì€ ì •í™•ë„ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. K-Neighbors ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•´ ë³´ì‹­ì‹œì˜¤.


1. ë¶„ë¥˜ì ë°°ì—´ì— ì¤„ì„ ì¶”ê°€í•©ë‹ˆë‹¤(ì„ í˜• SVC í•­ëª© ë’¤ì— ì‰¼í‘œ ì¶”ê°€)

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    The result is a little worse:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    âœ… Learn about [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## ì§€ì› ë²¡í„° ë¶„ë¥˜ê¸°

ì§€ì› ë²¡í„° ë¶„ë¥˜ê¸°ëŠ” ë‹¤ìŒì˜ ì¼ë¶€ì…ë‹ˆë‹¤.[Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine) ë¶„ë¥˜ ë° íšŒê·€ ì‘ì—…ì— ì‚¬ìš©ë˜ëŠ” ML ë°©ë²• ì œí’ˆêµ°ì…ë‹ˆë‹¤. SVMì€ ë‘ ë²”ì£¼ ê°„ì˜ ê±°ë¦¬ë¥¼ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ "ê³µê°„ì˜ ì§€ì ì— í›ˆë ¨ ì˜ˆì œë¥¼ ë§¤í•‘"í•©ë‹ˆë‹¤. í›„ì† ë°ì´í„°ëŠ” í•´ë‹¹ ë²”ì£¼ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ ì´ ê³µê°„ì— ë§¤í•‘ë©ë‹ˆë‹¤.

### ì§€ì› ë²¡í„° ë¶„ë¥˜ê¸° ì ìš©


Support Vector Classifierë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ë¥¼ ì¡°ê¸ˆ ë” ë†’ì—¬ ë³´ê² ìŠµë‹ˆë‹¤.


1. K-Neighbors í•­ëª© ë’¤ì— ì‰¼í‘œë¥¼ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì¤„ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

    ```python
    'SVC': SVC(),
    ```

   ê²°ê³¼ëŠ” ê½¤ ì¢‹ìŠµë‹ˆë‹¤!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    âœ… Learn about [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## ì•™ìƒë¸” ë¶„ë¥˜ê¸°


ì´ì „ í…ŒìŠ¤íŠ¸ëŠ” ê½¤ ê´œì°®ì•˜ì§€ë§Œ ëê¹Œì§€ ê°€ëŠ” ê¸¸ì„ ë”°ë¼ê°€ë³´ì. Ensemble Classifiers, íŠ¹íˆ Random Forest ë° AdaBoostë¥¼ ì‚¬ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

ê²°ê³¼ëŠ” íŠ¹íˆ Random Forestì˜ ê²½ìš° ë§¤ìš° ì¢‹ìŠµë‹ˆë‹¤.

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

âœ… Learn about [Ensemble Classifiers](https://scikit-learn.org/stable/modules/ensemble.html)

ë¨¸ì‹  ëŸ¬ë‹ì˜ ì´ ë°©ë²•ì€ "ì—¬ëŸ¬ ê¸°ë³¸ ì¶”ì •ê¸°ì˜ ì˜ˆì¸¡ì„ ê²°í•©"í•˜ì—¬ ëª¨ë¸ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ì˜ˆì—ì„œëŠ” Random Treesì™€ AdaBoostë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), í‰ê· í™” ë°©ë²•ì€ ê³¼ì í•©ì„ í”¼í•˜ê¸° ìœ„í•´ ì„ì˜ì„±ì´ ì£¼ì…ëœ 'ì˜ì‚¬ê²°ì • íŠ¸ë¦¬'ì˜ 'ìˆ²'ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. n_estimators ë§¤ê°œë³€ìˆ˜ëŠ” íŠ¸ë¦¬ ìˆ˜ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) 
ë¶„ë¥˜ê¸°ë¥¼ ë°ì´í„°ì„¸íŠ¸ì— ë§ì¶˜ ë‹¤ìŒ í•´ë‹¹ ë¶„ë¥˜ê¸°ì˜ ë³µì‚¬ë³¸ì„ ë™ì¼í•œ ë°ì´í„°ì„¸íŠ¸ì— ë§ì¶¥ë‹ˆë‹¤. ì˜ëª» ë¶„ë¥˜ëœ í•­ëª©ì˜ ê°€ì¤‘ì¹˜ì— ì´ˆì ì„ ë§ì¶”ê³  ë‹¤ìŒ ë¶„ë¥˜ê¸°ê°€ ìˆ˜ì •í•˜ë„ë¡ ë§ì¶¤ì„ ì¡°ì •í•©ë‹ˆë‹¤.

---

## ğŸš€Challenge

ì´ëŸ¬í•œ ê° ê¸°ìˆ ì—ëŠ” ì¡°ì •í•  ìˆ˜ ìˆëŠ” ë§ì€ ë§¤ê°œë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤. ê°ê°ì˜ ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì‚¬í•˜ê³  ì´ëŸ¬í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ë©´ ëª¨ë¸ í’ˆì§ˆì— ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€ ìƒê°í•´ ë³´ì„¸ìš”.

## [Post-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/24/)

## Review & Self Study

There's a lot of jargon in these lessons, so take a minute to review [this list](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-15963-cxa) of useful terminology!

## Assignment 

[Parameter play](assignment.md)
